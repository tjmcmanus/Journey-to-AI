{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Cloud Pak for Data and Netezza Performance Server to Build a Churn Predictive Model\n",
    "\n",
    "Cloud Pak for Data supports the entire Ladder to AI, including Collect, Organize, Analyze, and Infuse. Cloud Pak for Data enables companies to rapidly Modernize their applications on the Cloud of their choice, or on premise.\n",
    "\n",
    "Netezza Performance Server for PostgreSQL (NPS) is an add-on data warehouse solution available on Cloud Pak for Data System platform, built over open source and optimized for High Performance Analytics with built-in hardware acceleration.\n",
    "\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "You will learn how to:\n",
    "\n",
    "-  Load data from Netezza Performance Server into a pandas dataframe\n",
    "-  Explore data\n",
    "-  Prepare data for training and evaluation\n",
    "-  Create an XGBoost machine learning model\n",
    "-  Train and evaluate the model\n",
    "-  Use cross-validation to optimize model's hyperparameters\n",
    "-  Persist the model in a Cloud Pak for Data deployment space\n",
    "-  Deploy the model for online scoring\n",
    "-  Score test data\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "1.\t[Set up the environment](#setup)\n",
    "2.\t[Load and explore the data](#load)\n",
    "3.\t[Create an XGBoost model](#model)\n",
    "4.\t[Deploy and score the model in Cloud Pak for Data](#scoring)\n",
    "5.\t[Summary and next steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## 1. Set up the environment\n",
    "\n",
    "Install and import packages as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!pip install scikit-learn==0.19.1\n",
    "!pip install scikit-learn==0.20\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "!pip install 'xgboost==0.80'\n",
    "import xgboost\n",
    "xgboost.__version__\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load'></a>\n",
    "## 2. Load and explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will load the data into a pandas dataframe and perform an exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from NPS Performance Server\n",
    "\n",
    "# This code is auto generated from \"0100\" Icon on Upper Right > Connections > InsertToCode\n",
    "\n",
    "# This cell loads the Table: CUSTOMER_CHURN\n",
    "# @hidden_cell\n",
    "# This connection object is used to access your data and contains your credentials.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "\n",
    "from project_lib import Project\n",
    "project = Project.access()\n",
    "NPS_Database_credentials = project.get_connection(name=\"NPS_Database\")\n",
    "\n",
    "import jaydebeapi, pandas as pd\n",
    "NPS_Database_connection = jaydebeapi.connect('org.netezza.Driver',\n",
    "    '{}://{}:{}/{}'.format('jdbc:netezza',\n",
    "    NPS_Database_credentials['host'],\n",
    "    NPS_Database_credentials['port'],\n",
    "    NPS_Database_credentials['database']),\n",
    "    [NPS_Database_credentials['username'],\n",
    "    NPS_Database_credentials['password']])\n",
    "\n",
    "query = 'SELECT * FROM ADMIN.CUSTOMER_CHURN'\n",
    "data_df_1 = pd.read_sql(query, con=NPS_Database_connection)\n",
    "data_df_1.head()\n",
    "\n",
    "# You can close the database connection with the following code.\n",
    "# NPS_Database_connection.close()\n",
    "# To learn more about the jaydebeapi package, please read the documentation: https://pypi.org/project/JayDeBeApi/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data from NPS Performance Server\n",
    "\n",
    "# This code is auto generated from \"0100\" Icon on Upper Right > Connections > InsertToCode\n",
    "\n",
    "# This cell loads the Table: CUSTOMER_DEMOGRAPHICS\n",
    "query = 'SELECT * FROM ADMIN.CUSTOMER_DEMOGRAPHICS'\n",
    "data_df_2 = pd.read_sql(query, con=NPS_Database_connection)\n",
    "data_df_2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from NPS Performance Server\n",
    "\n",
    "# This code is auto generated from \"0100\" Icon on Upper Right > Connections > InsertToCode\n",
    "\n",
    "# This cell loads the Table: CUSTOMER_ACTIVITY\n",
    "query = 'SELECT * FROM ADMIN.CUSTOMER_ACTIVITY'\n",
    "data_df_3 = pd.read_sql(query, con=NPS_Database_connection)\n",
    "data_df_3.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the three tables using an inner join on the key field: ID\n",
    "\n",
    "df_4 = pd.merge(left=data_df_1, right=data_df_2, left_on='ID', right_on='ID')\n",
    "df = pd.merge(left=df_4, right=data_df_3, left_on='ID', right_on='ID')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code in the next cell to view the predictor names and data types.\n",
    "\n",
    "You can see that the data set has 569 data points and 31 predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about the data set, predictor names, and data types.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about values in the numerical columns.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the distribution of the target values/labels by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target values/labels.\n",
    "df['CHURNRISK'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NANs.\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make accurate predictions, you need to select the significant predictors by choosing the features that most affect the target: CHURNRISK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot a correlation heatmap\n",
    "plt.subplots(figsize=(25,20))\n",
    "hm1 = sns.heatmap(df.corr(), annot=True, cmap='YlGnBu')\n",
    "hm1.set_xticklabels(hm1.get_xticklabels(), rotation=90)\n",
    "hm1.xaxis.set_ticks_position('top')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This correlation heatmap helps with feature selection because the color gradient shows the correlation between the columns of the dataframe. In order to select only the *significant* predictors, you must eliminate features that are highly correlated with each other **(ex: > 0.95)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With respect to predicting the labels, the most significant predictors can be found by plotting boxplots of the numerical values against the labels. The features with boxplots that show the most variance should be chosen as the predictors for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot boxplots of numerical columns\n",
    "cont_list = ['CHILDREN', 'ESTINCOME', 'AGE', 'TOTALDALLARVALUETRADED', 'TOTALUNITSTRADED', 'LARGESTSINGLETRANSACTION', 'SMALLESTSINGLETRANSACTION', 'PERCENTCHANGECALCULATION', 'DAYSSINCELASTLOGIN', 'DAYSSINCELASTTRADE', 'NETREALIZEDGAINS_YTD', 'NETREALIZEDLOSSES_YTD']\n",
    "#cont_list = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'symmetry_mean', 'fractal_dimension_mean']\n",
    "f, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9), (ax10, ax11, ax12)) = plt.subplots(4, 3, figsize=(20, 25))\n",
    "ax = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9, ax10, ax11, ax12]\n",
    "\n",
    "for i in range(len(cont_list)):\n",
    "    sns.boxplot(x = 'CHURNRISK', y = cont_list[i], data=df, ax=ax[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model'></a>\n",
    "## 3. Create an XGBoost model\n",
    "\n",
    "In this section, you will learn how to train and test an XGBoost model.\n",
    "\n",
    "- [3.1 Split data](#prepare)\n",
    "- [3.2 Create an XGBoost model](#create)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By plotting the boxplots of each numerical column against the diagnosis type, we have picked out the significant features/predictors. More variation in the boxplot implies higher significance. We also eliminate features that are highly correlated. Therefore we can choose *radius_mean, radius_se, compactness_worst, concavity_mean, texture_mean* as the predictors for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Split data<a id='prepare'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will pass the data with the selected significant predictors to build the model. You will use the `diagnosis` column as your target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the inputs to the model\n",
    "\n",
    "# Define input data to the model\n",
    "X = df.drop(['GENDER','HOMEOWNER','STATUS','ID','CHURNRISK','TAXID','CREDITCARD','DOB','ADDRESS_1', 'ADDRESS_2', 'CITY', 'STATE', 'ZIP', 'ZIP4', 'LONGITUDE',\n",
    "       'LATITUDE'], axis=1)\n",
    "X = X.values\n",
    "\n",
    "# Changing the some variables to binary variables\n",
    "y = (df['CHURNRISK'] == 'High').astype(int)  # Converting from High, Medium, Low, to binary values representing High and Not-High\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set into: \n",
    "- Train data set\n",
    "- Test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data set and create two data sets.\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the number of records in each data set.\n",
    "print('Number of training records: ' + str(len(X_train)))\n",
    "print('Number of testing records : ' + str(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been successfully split into two data sets:\n",
    "- The train data set which is the largest group will be used for training.\n",
    "- The test data set will be used for model evaluation and is used to test the assumptions of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create an XGBoost model<a id='create'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Create an XGBoost classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection, you will create an XGBoost classifier with default hyperparameters and you will call *xgb_model*. \n",
    "\n",
    "**Note**: The next sections show you how to improve this base model.\n",
    "\n",
    "In this first building of the model will use 100 iterations. Then we'll examine how accuracy varies over the iterations. Finally, we'll rebuild the model using the number of iterations that leads to and accurate, but not overfit, model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the XGB classifier - xgb_model.\n",
    "xgb_model = XGBClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the default parameters for *xgb_model*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the default parameters.\n",
    "print(xgb_model.get_xgb_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that your XGBoost classifier *xgb_model* is set up, you can train it by using the fit method. You will also evaluate *xgb_model* as the train and test data are being trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train and evaluate.\n",
    "xgb_model.fit(X_train, y_train, eval_metric=['error'], eval_set=[((X_train, y_train)),(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the model performance evaluated during the training process to assess model overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and display the performance evaluation\n",
    "xgb_eval = xgb_model.evals_result()\n",
    "eval_steps = range(len(xgb_eval['validation_0']['error']))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, sharex=True, figsize=(8, 6))\n",
    "\n",
    "ax.plot(eval_steps, [1-x for x in xgb_eval['validation_0']['error']], label='Train')\n",
    "ax.plot(eval_steps, [1-x for x in xgb_eval['validation_1']['error']], label='Test')\n",
    "ax.legend()\n",
    "ax.set_title('Accuracy')\n",
    "ax.set_xlabel('Number of iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there is model overfitting, and there is no increase in model accuracy after about 35 iterations.\n",
    "\n",
    "So let's rebuild the model using 35 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(n_estimators=35)\n",
    "xgb_model.fit(X_train, y_train, eval_metric=['error'], eval_set=[((X_train, y_train)),(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's plot the model performance evaluated during the training process to assess model overfitting. This looks alot better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and display the performance evaluation\n",
    "xgb_eval = xgb_model.evals_result()\n",
    "eval_steps = range(len(xgb_eval['validation_0']['error']))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, sharex=True, figsize=(8, 6))\n",
    "\n",
    "ax.plot(eval_steps, [1-x for x in xgb_eval['validation_0']['error']], label='Train')\n",
    "ax.plot(eval_steps, [1-x for x in xgb_eval['validation_1']['error']], label='Test')\n",
    "ax.legend()\n",
    "ax.set_title('Accuracy')\n",
    "ax.set_xlabel('Number of iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select trained model.\n",
    "n_trees = 35\n",
    "y_pred = xgb_model.predict(X_test, ntree_limit= n_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy of the trained model.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %.2f%%' % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You will use the test data accuracy to compare the accuracy of the model with *default* parameters to the accuracy of the model with *tuned* parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.matshow(cm)\n",
    "plt.colorbar()\n",
    "plt.xlabel('Actual values')\n",
    "plt.ylabel('Predicted values')\n",
    "plt.show()\n",
    "pd.DataFrame(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confusion matrix maps the predicted values against the actual values. Here, you can see that 126 benign tumors and 66 malignant tumors have been predicted correctly. However, 8 benign tumors have been incorrectly predicted as malignant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = xgb_model.predict_proba(X_test)\n",
    "\n",
    "# ROC-AUC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob[:, 1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the ROC-AUC curve - the area under the curve represents the accuracy of the predictions. You can see that the area under the curve is large, indicating that the predictions are highly accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Use grid search and cross-validation to tune the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use grid search and cross-validation to tune your model to achieve better accuracy.\n",
    "\n",
    "**Note**: Grid search is used for this model as an example, but it is **not** recommended for small data sets such as this one, as it might lead to overfitting.\n",
    "\n",
    "XGBoost has an extensive catalog of hyperparameters which provides great flexibility to shape an algorithm’s desired behavior. Here you will the optimize the model tuning which adds an L1 penalty (`reg_alpha`).\n",
    "\n",
    "Use a 5-fold cross-validation because your training data set is small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, create the XGBoost pipeline and set up the parameter grid for the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGBoost pipeline, set up parameter grid.\n",
    "xgb_model_gs = XGBClassifier()\n",
    "parameters = {'reg_alpha': [0.0, 1.0, 2.0], 'reg_lambda': [0.0, 1.0, 2.0], 'n_estimators': [n_trees], 'seed': [1337]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ``GridSearchCV`` to search for the best parameters from the specified values in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Search for the best parameters.\n",
    "clf = GridSearchCV(estimator = xgb_model_gs, param_grid = parameters, scoring='accuracy', cv=5, verbose=1, n_jobs=1, refit=True)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the cross validation results that were evaluated by the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print model cross validation results.\n",
    "for key in ['params', 'mean_train_score', 'std_train_score', 'mean_test_score', 'std_test_score']:\n",
    "    print(str(key) + ': \\n' + str(clf.cv_results_[key]) + '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the accuracy estimated using cross-validation and the hyperparameter values for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Best score: %.1f%%' % (clf.best_score_*100))\n",
    "print('Best parameter set: %s' % (clf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the accuracy of the best parameter combination on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.best_estimator_.predict(X_test, ntree_limit= n_trees)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %.2f%%' % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set's accuracy is about the same for both the tuned model and the trained model with default hyperparameter values, even though the tuned hyperparameters are different from the default parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Deploy and Score the Model In Cloud Pak for Data <a id=\"scoring\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will learn how to deploy and use models in Cloud Pak for Data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we save the model we must create a deployment space. Cloud Pak for Data provides deployment spaces where the user can save, configure and deploy their models. We can save models, functions and data assets in this space.\n",
    "\n",
    "The steps involved for saving and deploying the model are as follows:\n",
    "\n",
    "1. Create a new deployment space. Enter the name of the space in the cell below. Specify a tag for the space in the code cell below. This tag will be used in the future to identify this space. If a space with specified space_name already exists, existing space will be deleted before creating a new space.\n",
    "2. Set this deployment space as the default space.\n",
    "3. Store the model pipeline in the deployment space. Enter the name for the model in the cell below. Specify a tag for the model in the cell below.\n",
    "4. Deploy the saved model. Enter the deployment name in the cell below. Specifu a tag for the deployment. Similarily, this tag will be used in the future to identify this deployment.\n",
    "5. Retrieve the scoring endpoint to score the model with a payload\n",
    "5. We will use the watson_machine_learning_client package to complete these steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a names for the space being created, the saved model and the model deployment\n",
    "space_name = 'Deployment-Space-Created-From-Notebook'\n",
    "space_tag = 'Deployment-Space-Created-From-Notebook-tag'\n",
    "\n",
    "model_name = 'Churn-Model'\n",
    "model_tag = 'Churn-Model-tag'\n",
    "\n",
    "deployment_name = 'Churn-Model-Deployment'\n",
    "deployment_tag = 'Churn-Model-Deployment-Tag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "import os\n",
    "\n",
    "token = os.environ['USER_ACCESS_TOKEN']\n",
    "\n",
    "wml_credentials = {\n",
    "   \"token\": token,\n",
    "   \"instance_id\" : \"openshift\",\n",
    "   \"url\": os.environ['RUNTIME_ENV_APSX_URL'],\n",
    "   \"version\": \"3.0.0\"\n",
    "}\n",
    "\n",
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a space with specified space_name already exists, delete the existing space before creating a new one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for space in client.spaces.get_details()['resources']:\n",
    "    if space_name in space['entity']['name']:\n",
    "        client.spaces.delete(space['metadata']['guid'])\n",
    "        print(space_name, \"is deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Create Deployment Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the space and set it as default\n",
    "space_meta_data = {\n",
    "        client.spaces.ConfigurationMetaNames.NAME : space_name,\n",
    "        client.spaces.ConfigurationMetaNames.TAGS : [{'value': space_tag}]\n",
    "}\n",
    "\n",
    "stored_space_details = client.spaces.store(space_meta_data)\n",
    "\n",
    "space_uid = stored_space_details['metadata']['guid']\n",
    "\n",
    "# set the newly created deployment space as the default\n",
    "client.set.default_space(space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching details of the space created\n",
    "stored_space_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Store the model in the deployment space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this line if you do not know the version of scikit-learn that was used to build the model\n",
    "!pip list | grep scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    client.repository.ModelMetaNames.NAME: model_name,\n",
    "    client.repository.ModelMetaNames.TYPE: \"scikit-learn_0.20\",\n",
    "    client.repository.ModelMetaNames.RUNTIME_UID: \"scikit-learn_0.20-py3\",\n",
    "    client.repository.ModelMetaNames.TAGS: [{'value' : model_tag}],\n",
    "    client.repository.ModelMetaNames.SPACE_UID: space_uid\n",
    "}\n",
    "\n",
    "stored_model_details = client.repository.store_model(xgb_model,\n",
    "                                               meta_props=metadata,\n",
    "                                               training_data=X_train,\n",
    "                                               training_target=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_model_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Create a deployment for the stored model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy the model for on-line use\n",
    "meta_props = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: deployment_name,\n",
    "    client.deployments.ConfigurationMetaNames.TAGS : [{'value' : deployment_tag}],\n",
    "    client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "}\n",
    "\n",
    "# deploy the model\n",
    "\n",
    "model_uid = stored_model_details[\"metadata\"][\"guid\"]\n",
    "deployment_details = client.deployments.create( artifact_uid=model_uid, meta_props=meta_props)\n",
    "deployment_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Score Using the Deployed, On-line Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the scoring endpoint\n",
    "scoring_endpoint = client.deployments.get_scoring_href(deployment_details)\n",
    "\n",
    "print('Scoring Endpoint:   ',scoring_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_deployment_id = client.deployments.get_uid(deployment_details)\n",
    "client.deployments.get_details(scoring_deployment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = [{\"values\": [ [1, 38000, 24, 1200000, 509, 9400, 940, 51, 3, 10, 0, -81000]]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_metadata = {client.deployments.ScoringMetaNames.INPUT_DATA: payload}\n",
    "# score\n",
    "predictions = client.deployments.score(scoring_deployment_id, payload_metadata)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "## 5. Conclusion     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have successfully completed this notebook! \n",
    "\n",
    "You learned how to use Cloud Pak for Data with Netezza Performance Server. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "\n",
    "Tom Konchan, a Data Scientist at IBM derived this notebook from a notebook found in the Watson Studio Gallery: [Use XGBoost to classify tumors](https://dataplatform.cloud.ibm.com/exchange/public/entry/view/30b8df0ef74241a0516f9e81cd6d7029). It was originally developed by:\n",
    "\n",
    "**Wojciech Sobala**, a Data Scientist at IBM.  \n",
    "**Ananya Kaushik**, a Data Scientist at IBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2017-2019 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background:#F5F7FA; height:110px; padding: 2em; font-size:14px;'>\n",
    "<span style='font-size:18px;color:#152935;'>Love this notebook? </span>\n",
    "<span style='font-size:15px;color:#152935;float:right;margin-right:40px;'>Don't have an account yet?</span><br>\n",
    "<span style='color:#5A6872;'>Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style='border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;'><a href='https://ibm.co/wsnotebooks' target='_blank' style='color: #3d70b2;text-decoration: none;'>Sign Up</a></span><br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
